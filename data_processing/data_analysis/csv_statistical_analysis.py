#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CSVæ•°æ®ç»Ÿè®¡åˆ†æç¤ºä¾‹
ä½¿ç”¨é¢å‘è¿‡ç¨‹ç¼–ç¨‹ï¼Œæ¼”ç¤ºå¸¸è§çš„æ•°æ®ç»Ÿè®¡åˆ†ææ“ä½œ
"""

import pandas as pd
import numpy as np
import os

def load_data(file_path):
    """
    åŠ è½½CSVæ•°æ®
    """
    try:
        df = pd.read_csv(file_path, encoding='utf-8')
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {df.shape[0]}è¡Œ {df.shape[1]}åˆ—")
        return df
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None

def basic_statistics(df, data_name="æ•°æ®"):
    """
    åŸºç¡€ç»Ÿè®¡åˆ†æ
    """
    print(f"\nğŸ“Š {data_name}åŸºç¡€ç»Ÿè®¡åˆ†æ")
    print("-" * 40)
    
    # æ•°å€¼åˆ—ç»Ÿè®¡
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    if len(numeric_columns) > 0:
        print("æ•°å€¼åˆ—ç»Ÿè®¡ä¿¡æ¯:")
        stats = df[numeric_columns].describe()
        print(stats)
        
        # é¢å¤–ç»Ÿè®¡ä¿¡æ¯
        print(f"\nè¯¦ç»†ç»Ÿè®¡:")
        for col in numeric_columns:
            data = df[col]
            print(f"\n{col}åˆ—:")
            print(f"  æ€»æ•°: {data.count()}")
            print(f"  å‡å€¼: {data.mean():.2f}")
            print(f"  ä¸­ä½æ•°: {data.median():.2f}")
            print(f"  ä¼—æ•°: {data.mode().iloc[0] if len(data.mode()) > 0 else 'æ— '}")
            print(f"  æ ‡å‡†å·®: {data.std():.2f}")
            print(f"  æ–¹å·®: {data.var():.2f}")
            print(f"  æœ€å°å€¼: {data.min()}")
            print(f"  æœ€å¤§å€¼: {data.max()}")
            print(f"  èŒƒå›´: {data.max() - data.min()}")

def categorical_analysis(df, data_name="æ•°æ®"):
    """
    åˆ†ç±»æ•°æ®åˆ†æ
    """
    print(f"\nğŸ“ˆ {data_name}åˆ†ç±»æ•°æ®åˆ†æ")
    print("-" * 40)
    
    # æ–‡æœ¬åˆ—åˆ†æ
    text_columns = df.select_dtypes(include=['object']).columns
    
    for col in text_columns:
        print(f"\n{col}åˆ—åˆ†æ:")
        value_counts = df[col].value_counts()
        print(f"  å”¯ä¸€å€¼æ•°é‡: {df[col].nunique()}")
        print(f"  é¢‘æ¬¡ç»Ÿè®¡:")
        for value, count in value_counts.items():
            percentage = (count / len(df)) * 100
            print(f"    {value}: {count}æ¬¡ ({percentage:.1f}%)")

def group_analysis(df, group_column, target_column, data_name="æ•°æ®"):
    """
    åˆ†ç»„åˆ†æ
    """
    print(f"\nğŸ” {data_name}åˆ†ç»„åˆ†æ: æŒ‰{group_column}åˆ†ç»„åˆ†æ{target_column}")
    print("-" * 50)
    
    # æŒ‰ç»„ç»Ÿè®¡
    grouped = df.groupby(group_column)[target_column]
    
    print("åˆ†ç»„ç»Ÿè®¡ç»“æœ:")
    group_stats = grouped.agg(['count', 'mean', 'median', 'std', 'min', 'max'])
    print(group_stats)
    
    # è¯¦ç»†åˆ†ç»„ä¿¡æ¯
    print(f"\nè¯¦ç»†åˆ†ç»„ä¿¡æ¯:")
    for group_name, group_data in df.groupby(group_column):
        target_data = group_data[target_column]
        print(f"\n{group_column} = {group_name}:")
        print(f"  äººæ•°: {len(group_data)}")
        print(f"  {target_column}å‡å€¼: {target_data.mean():.2f}")
        print(f"  {target_column}ä¸­ä½æ•°: {target_data.median():.2f}")
        print(f"  {target_column}æœ€å¤§å€¼: {target_data.max()}")
        print(f"  {target_column}æœ€å°å€¼: {target_data.min()}")

def correlation_analysis(df, data_name="æ•°æ®"):
    """
    ç›¸å…³æ€§åˆ†æ
    """
    print(f"\nğŸ”— {data_name}ç›¸å…³æ€§åˆ†æ")
    print("-" * 40)
    
    # åªåˆ†ææ•°å€¼åˆ—
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    
    if len(numeric_columns) < 2:
        print("æ•°å€¼åˆ—å°‘äº2ä¸ªï¼Œæ— æ³•è¿›è¡Œç›¸å…³æ€§åˆ†æ")
        return
    
    # è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ
    correlation_matrix = df[numeric_columns].corr()
    print("ç›¸å…³ç³»æ•°çŸ©é˜µ:")
    print(correlation_matrix)
    
    # æ‰¾å‡ºå¼ºç›¸å…³å…³ç³»
    print(f"\nå¼ºç›¸å…³å…³ç³» (|ç›¸å…³ç³»æ•°| > 0.7):")
    for i in range(len(numeric_columns)):
        for j in range(i+1, len(numeric_columns)):
            col1 = numeric_columns[i]
            col2 = numeric_columns[j]
            corr_value = correlation_matrix.loc[col1, col2]
            if abs(corr_value) > 0.7:
                relationship = "æ­£ç›¸å…³" if corr_value > 0 else "è´Ÿç›¸å…³"
                print(f"  {col1} ä¸ {col2}: {corr_value:.3f} ({relationship})")

def percentile_analysis(df, column, data_name="æ•°æ®"):
    """
    ç™¾åˆ†ä½æ•°åˆ†æ
    """
    print(f"\nğŸ“ {data_name}{column}åˆ—ç™¾åˆ†ä½æ•°åˆ†æ")
    print("-" * 40)
    
    data = df[column]
    percentiles = [10, 25, 50, 75, 90, 95, 99]
    
    print("ç™¾åˆ†ä½æ•°åˆ†å¸ƒ:")
    for p in percentiles:
        value = np.percentile(data, p)
        print(f"  {p}%åˆ†ä½æ•°: {value:.2f}")
    
    # åˆ†ææ•°æ®åˆ†å¸ƒ
    q1 = np.percentile(data, 25)
    q3 = np.percentile(data, 75)
    iqr = q3 - q1
    
    print(f"\nåˆ†å¸ƒç‰¹å¾:")
    print(f"  å››åˆ†ä½è·(IQR): {iqr:.2f}")
    print(f"  ä¸‹å››åˆ†ä½æ•°(Q1): {q1:.2f}")
    print(f"  ä¸Šå››åˆ†ä½æ•°(Q3): {q3:.2f}")

def outlier_detection(df, column, data_name="æ•°æ®"):
    """
    å¼‚å¸¸å€¼æ£€æµ‹
    """
    print(f"\nğŸ¯ {data_name}{column}åˆ—å¼‚å¸¸å€¼æ£€æµ‹")
    print("-" * 40)
    
    data = df[column]
    
    # ä½¿ç”¨IQRæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼
    Q1 = data.quantile(0.25)
    Q3 = data.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    outliers = data[(data < lower_bound) | (data > upper_bound)]
    
    print(f"IQRæ–¹æ³•å¼‚å¸¸å€¼æ£€æµ‹:")
    print(f"  æ­£å¸¸èŒƒå›´: {lower_bound:.2f} - {upper_bound:.2f}")
    print(f"  å¼‚å¸¸å€¼æ•°é‡: {len(outliers)}")
    
    if len(outliers) > 0:
        print(f"  å¼‚å¸¸å€¼åˆ—è¡¨: {outliers.tolist()}")
    
    # ä½¿ç”¨Z-scoreæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼
    z_scores = np.abs((data - data.mean()) / data.std())
    z_outliers = data[z_scores > 3]
    
    print(f"\nZ-scoreæ–¹æ³•å¼‚å¸¸å€¼æ£€æµ‹ (|Z| > 3):")
    print(f"  å¼‚å¸¸å€¼æ•°é‡: {len(z_outliers)}")
    if len(z_outliers) > 0:
        print(f"  å¼‚å¸¸å€¼åˆ—è¡¨: {z_outliers.tolist()}")

def trend_analysis(df, date_column, value_column, data_name="æ•°æ®"):
    """
    è¶‹åŠ¿åˆ†æï¼ˆå¦‚æœæœ‰æ—¥æœŸåˆ—ï¼‰
    """
    print(f"\nğŸ“ˆ {data_name}è¶‹åŠ¿åˆ†æ")
    print("-" * 40)
    
    try:
        # è½¬æ¢æ—¥æœŸåˆ—
        df_copy = df.copy()
        df_copy[date_column] = pd.to_datetime(df_copy[date_column])
        
        # æŒ‰æ—¥æœŸæ’åº
        df_sorted = df_copy.sort_values(date_column)
        
        # è®¡ç®—å˜åŒ–è¶‹åŠ¿
        values = df_sorted[value_column].values
        if len(values) > 1:
            # è®¡ç®—æ€»ä½“è¶‹åŠ¿
            first_value = values[0]
            last_value = values[-1]
            total_change = last_value - first_value
            change_percentage = (total_change / first_value) * 100
            
            print(f"è¶‹åŠ¿åˆ†æç»“æœ:")
            print(f"  èµ·å§‹å€¼: {first_value}")
            print(f"  ç»“æŸå€¼: {last_value}")
            print(f"  æ€»å˜åŒ–: {total_change:.2f}")
            print(f"  å˜åŒ–ç™¾åˆ†æ¯”: {change_percentage:.2f}%")
            
            # åˆ¤æ–­è¶‹åŠ¿æ–¹å‘
            if change_percentage > 5:
                trend = "ä¸Šå‡è¶‹åŠ¿"
            elif change_percentage < -5:
                trend = "ä¸‹é™è¶‹åŠ¿"
            else:
                trend = "ç›¸å¯¹ç¨³å®š"
            
            print(f"  è¶‹åŠ¿åˆ¤æ–­: {trend}")
            
    except Exception as e:
        print(f"æ— æ³•è¿›è¡Œè¶‹åŠ¿åˆ†æ: {e}")

def generate_summary_report(df, data_name="æ•°æ®"):
    """
    ç”Ÿæˆæ•°æ®åˆ†ææ‘˜è¦æŠ¥å‘Š
    """
    print(f"\nğŸ“‹ {data_name}åˆ†ææ‘˜è¦æŠ¥å‘Š")
    print("=" * 50)
    
    # åŸºæœ¬ä¿¡æ¯
    print(f"æ•°æ®æ¦‚å†µ:")
    print(f"  æ€»è¡Œæ•°: {len(df)}")
    print(f"  æ€»åˆ—æ•°: {len(df.columns)}")
    print(f"  æ•°å€¼åˆ—æ•°: {len(df.select_dtypes(include=[np.number]).columns)}")
    print(f"  æ–‡æœ¬åˆ—æ•°: {len(df.select_dtypes(include=['object']).columns)}")
    
    # æ•°æ®è´¨é‡
    missing_count = df.isnull().sum().sum()
    duplicate_count = df.duplicated().sum()
    
    print(f"\næ•°æ®è´¨é‡:")
    print(f"  ç¼ºå¤±å€¼æ€»æ•°: {missing_count}")
    print(f"  é‡å¤è¡Œæ•°: {duplicate_count}")
    print(f"  æ•°æ®å®Œæ•´æ€§: {((len(df) * len(df.columns) - missing_count) / (len(df) * len(df.columns))) * 100:.1f}%")
    
    # å…³é”®ç»Ÿè®¡
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    if len(numeric_columns) > 0:
        print(f"\nå…³é”®ç»Ÿè®¡æŒ‡æ ‡:")
        for col in numeric_columns:
            data = df[col]
            print(f"  {col}: å‡å€¼={data.mean():.2f}, ä¸­ä½æ•°={data.median():.2f}, æ ‡å‡†å·®={data.std():.2f}")

def main():
    """
    ä¸»å‡½æ•° - æ¼”ç¤ºæ•°æ®ç»Ÿè®¡åˆ†æ
    """
    print("ğŸš€ å¼€å§‹CSVæ•°æ®ç»Ÿè®¡åˆ†æç¤ºä¾‹")
    
    # è®¾ç½®æ–‡ä»¶è·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    sample_data_dir = os.path.join(os.path.dirname(current_dir), "sample_data")
    
    employees_file = os.path.join(sample_data_dir, "employees.csv")
    products_file = os.path.join(sample_data_dir, "products.csv")
    
    # åˆ†æå‘˜å·¥æ•°æ®
    print("\n" + "="*60)
    print("ğŸ‘¥ å‘˜å·¥æ•°æ®ç»Ÿè®¡åˆ†æ")
    print("="*60)
    
    employees_df = load_data(employees_file)
    if employees_df is not None:
        basic_statistics(employees_df, "å‘˜å·¥")
        categorical_analysis(employees_df, "å‘˜å·¥")
        group_analysis(employees_df, 'éƒ¨é—¨', 'å·¥èµ„', "å‘˜å·¥")
        percentile_analysis(employees_df, 'å·¥èµ„', "å‘˜å·¥")
        outlier_detection(employees_df, 'å·¥èµ„', "å‘˜å·¥")
        outlier_detection(employees_df, 'å¹´é¾„', "å‘˜å·¥")
        trend_analysis(employees_df, 'å…¥èŒæ—¥æœŸ', 'å·¥èµ„', "å‘˜å·¥")
        generate_summary_report(employees_df, "å‘˜å·¥")
    
    # åˆ†æå•†å“æ•°æ®
    print("\n" + "="*60)
    print("ğŸ›ï¸ å•†å“æ•°æ®ç»Ÿè®¡åˆ†æ")
    print("="*60)
    
    products_df = load_data(products_file)
    if products_df is not None:
        basic_statistics(products_df, "å•†å“")
        categorical_analysis(products_df, "å•†å“")
        group_analysis(products_df, 'ç±»åˆ«', 'ä»·æ ¼', "å•†å“")
        group_analysis(products_df, 'ç±»åˆ«', 'é”€å”®é‡', "å•†å“")
        correlation_analysis(products_df, "å•†å“")
        percentile_analysis(products_df, 'ä»·æ ¼', "å•†å“")
        outlier_detection(products_df, 'ä»·æ ¼', "å•†å“")
        generate_summary_report(products_df, "å•†å“")
    
    print("\nğŸ‰ æ•°æ®ç»Ÿè®¡åˆ†æç¤ºä¾‹å®Œæˆï¼")
    print("\nğŸ“Š åˆ†æå†…å®¹æ€»ç»“:")
    print("1. âœ… åŸºç¡€ç»Ÿè®¡åˆ†æ")
    print("2. âœ… åˆ†ç±»æ•°æ®åˆ†æ")
    print("3. âœ… åˆ†ç»„åˆ†æ")
    print("4. âœ… ç›¸å…³æ€§åˆ†æ")
    print("5. âœ… ç™¾åˆ†ä½æ•°åˆ†æ")
    print("6. âœ… å¼‚å¸¸å€¼æ£€æµ‹")
    print("7. âœ… è¶‹åŠ¿åˆ†æ")
    print("8. âœ… æ‘˜è¦æŠ¥å‘Šç”Ÿæˆ")

if __name__ == "__main__":
    main()