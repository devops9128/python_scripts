#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CSVæ•°æ®èšåˆå’Œæ±‡æ€»ç¤ºä¾‹
ä½¿ç”¨é¢å‘è¿‡ç¨‹ç¼–ç¨‹ï¼Œæ¼”ç¤ºæ•°æ®èšåˆã€åˆ†ç»„æ±‡æ€»ç­‰æ“ä½œ
"""

import pandas as pd
import numpy as np
import os

def load_data(file_path):
    """
    åŠ è½½CSVæ•°æ®
    """
    try:
        df = pd.read_csv(file_path, encoding='utf-8')
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {df.shape[0]}è¡Œ {df.shape[1]}åˆ—")
        return df
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None

def create_extended_sample_data():
    """
    åˆ›å»ºæ‰©å±•çš„ç¤ºä¾‹æ•°æ®ç”¨äºèšåˆåˆ†æ
    """
    print("ğŸ”§ åˆ›å»ºæ‰©å±•ç¤ºä¾‹æ•°æ®...")
    
    # é”€å”®æ•°æ®
    sales_data = {
        'æ—¥æœŸ': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04', '2024-01-05',
                '2024-01-06', '2024-01-07', '2024-01-08', '2024-01-09', '2024-01-10',
                '2024-02-01', '2024-02-02', '2024-02-03', '2024-02-04', '2024-02-05'],
        'é”€å”®å‘˜': ['å¼ ä¸‰', 'æå››', 'ç‹äº”', 'å¼ ä¸‰', 'æå››', 'ç‹äº”', 'å¼ ä¸‰', 'æå››', 'ç‹äº”', 'å¼ ä¸‰',
                 'æå››', 'ç‹äº”', 'å¼ ä¸‰', 'æå››', 'ç‹äº”'],
        'äº§å“': ['è‹¹æœ', 'é¦™è•‰', 'è‹¹æœ', 'æ©™å­', 'è‹¹æœ', 'é¦™è•‰', 'æ©™å­', 'è‹¹æœ', 'æ©™å­', 'é¦™è•‰',
               'è‹¹æœ', 'æ©™å­', 'é¦™è•‰', 'è‹¹æœ', 'æ©™å­'],
        'æ•°é‡': [10, 15, 8, 12, 20, 18, 6, 14, 9, 16, 11, 13, 17, 19, 7],
        'å•ä»·': [5.5, 3.2, 5.5, 4.8, 5.5, 3.2, 4.8, 5.5, 4.8, 3.2, 5.5, 4.8, 3.2, 5.5, 4.8],
        'åœ°åŒº': ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'åŒ—äº¬',
               'ä¸Šæµ·', 'å¹¿å·', 'åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·']
    }
    
    df = pd.DataFrame(sales_data)
    df['é”€å”®é¢'] = df['æ•°é‡'] * df['å•ä»·']
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
    
    return df

def basic_aggregation(df, data_name="æ•°æ®"):
    """
    åŸºç¡€èšåˆæ“ä½œ
    """
    print(f"\nğŸ“Š {data_name}åŸºç¡€èšåˆåˆ†æ")
    print("-" * 40)
    
    # æ€»ä½“ç»Ÿè®¡
    print("æ€»ä½“ç»Ÿè®¡:")
    print(f"  æ€»é”€å”®é¢: {df['é”€å”®é¢'].sum():.2f}")
    print(f"  å¹³å‡é”€å”®é¢: {df['é”€å”®é¢'].mean():.2f}")
    print(f"  æœ€å¤§å•ç¬”é”€å”®: {df['é”€å”®é¢'].max():.2f}")
    print(f"  æœ€å°å•ç¬”é”€å”®: {df['é”€å”®é¢'].min():.2f}")
    print(f"  æ€»é”€å”®æ•°é‡: {df['æ•°é‡'].sum()}")
    print(f"  å¹³å‡é”€å”®æ•°é‡: {df['æ•°é‡'].mean():.2f}")

def group_by_single_column(df, group_column, agg_column, data_name="æ•°æ®"):
    """
    æŒ‰å•åˆ—åˆ†ç»„èšåˆ
    """
    print(f"\nğŸ” {data_name}æŒ‰{group_column}åˆ†ç»„èšåˆ")
    print("-" * 40)
    
    # åŸºç¡€åˆ†ç»„ç»Ÿè®¡
    grouped = df.groupby(group_column)[agg_column].agg(['sum', 'mean', 'count', 'max', 'min'])
    print(f"æŒ‰{group_column}åˆ†ç»„çš„{agg_column}ç»Ÿè®¡:")
    print(grouped)
    
    # æ’åºæ˜¾ç¤º
    print(f"\næŒ‰{agg_column}æ€»å’Œæ’åº:")
    sorted_groups = grouped.sort_values('sum', ascending=False)
    print(sorted_groups)

def group_by_multiple_columns(df, group_columns, agg_column, data_name="æ•°æ®"):
    """
    æŒ‰å¤šåˆ—åˆ†ç»„èšåˆ
    """
    print(f"\nğŸ” {data_name}æŒ‰{group_columns}å¤šåˆ—åˆ†ç»„èšåˆ")
    print("-" * 50)
    
    # å¤šåˆ—åˆ†ç»„
    grouped = df.groupby(group_columns)[agg_column].agg(['sum', 'mean', 'count'])
    print(f"æŒ‰{group_columns}åˆ†ç»„çš„{agg_column}ç»Ÿè®¡:")
    print(grouped)
    
    # é‡ç½®ç´¢å¼•ä»¥ä¾¿æ›´å¥½åœ°æŸ¥çœ‹
    grouped_reset = grouped.reset_index()
    print(f"\né‡ç½®ç´¢å¼•åçš„ç»“æœ:")
    print(grouped_reset)

def custom_aggregation(df, data_name="æ•°æ®"):
    """
    è‡ªå®šä¹‰èšåˆå‡½æ•°
    """
    print(f"\nğŸ› ï¸ {data_name}è‡ªå®šä¹‰èšåˆåˆ†æ")
    print("-" * 40)
    
    # è‡ªå®šä¹‰èšåˆå‡½æ•°
    def sales_summary(series):
        return pd.Series({
            'æ€»é”€å”®é¢': series.sum(),
            'å¹³å‡é”€å”®é¢': series.mean(),
            'é”€å”®æ¬¡æ•°': series.count(),
            'æœ€å¤§é”€å”®': series.max(),
            'æœ€å°é”€å”®': series.min(),
            'é”€å”®èŒƒå›´': series.max() - series.min(),
            'æ ‡å‡†å·®': series.std()
        })
    
    # æŒ‰é”€å”®å‘˜åˆ†ç»„åº”ç”¨è‡ªå®šä¹‰å‡½æ•°
    custom_agg = df.groupby('é”€å”®å‘˜')['é”€å”®é¢'].apply(sales_summary)
    print("é”€å”®å‘˜é”€å”®æƒ…å†µè¯¦ç»†åˆ†æ:")
    print(custom_agg)

def pivot_table_analysis(df, data_name="æ•°æ®"):
    """
    æ•°æ®é€è§†è¡¨åˆ†æ
    """
    print(f"\nğŸ“‹ {data_name}æ•°æ®é€è§†è¡¨åˆ†æ")
    print("-" * 40)
    
    # åˆ›å»ºæ•°æ®é€è§†è¡¨ï¼šé”€å”®å‘˜ vs äº§å“
    pivot1 = pd.pivot_table(df, 
                           values='é”€å”®é¢', 
                           index='é”€å”®å‘˜', 
                           columns='äº§å“', 
                           aggfunc='sum', 
                           fill_value=0)
    print("é”€å”®å‘˜ vs äº§å“é”€å”®é¢é€è§†è¡¨:")
    print(pivot1)
    
    # æ·»åŠ æ€»è®¡è¡Œå’Œåˆ—
    pivot1_with_totals = pivot1.copy()
    pivot1_with_totals['æ€»è®¡'] = pivot1_with_totals.sum(axis=1)
    pivot1_with_totals.loc['æ€»è®¡'] = pivot1_with_totals.sum()
    print(f"\nå¸¦æ€»è®¡çš„é€è§†è¡¨:")
    print(pivot1_with_totals)
    
    # åˆ›å»ºæ•°æ®é€è§†è¡¨ï¼šåœ°åŒº vs äº§å“
    pivot2 = pd.pivot_table(df, 
                           values=['é”€å”®é¢', 'æ•°é‡'], 
                           index='åœ°åŒº', 
                           columns='äº§å“', 
                           aggfunc={'é”€å”®é¢': 'sum', 'æ•°é‡': 'sum'}, 
                           fill_value=0)
    print(f"\nåœ°åŒº vs äº§å“å¤šæŒ‡æ ‡é€è§†è¡¨:")
    print(pivot2)

def time_based_aggregation(df, data_name="æ•°æ®"):
    """
    åŸºäºæ—¶é—´çš„èšåˆåˆ†æ
    """
    print(f"\nğŸ“… {data_name}æ—¶é—´åºåˆ—èšåˆåˆ†æ")
    print("-" * 40)
    
    # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
    
    # æŒ‰æ—¥æœŸèšåˆ
    daily_sales = df.groupby('æ—¥æœŸ')['é”€å”®é¢'].sum()
    print("æ¯æ—¥é”€å”®é¢:")
    print(daily_sales)
    
    # æŒ‰æœˆèšåˆ
    df['æœˆä»½'] = df['æ—¥æœŸ'].dt.to_period('M')
    monthly_sales = df.groupby('æœˆä»½')['é”€å”®é¢'].agg(['sum', 'mean', 'count'])
    print(f"\næ¯æœˆé”€å”®ç»Ÿè®¡:")
    print(monthly_sales)
    
    # æŒ‰æ˜ŸæœŸå‡ èšåˆ
    df['æ˜ŸæœŸå‡ '] = df['æ—¥æœŸ'].dt.day_name()
    weekday_sales = df.groupby('æ˜ŸæœŸå‡ ')['é”€å”®é¢'].sum()
    print(f"\næŒ‰æ˜ŸæœŸå‡ é”€å”®ç»Ÿè®¡:")
    print(weekday_sales)

def rolling_aggregation(df, data_name="æ•°æ®"):
    """
    æ»šåŠ¨çª—å£èšåˆ
    """
    print(f"\nğŸ”„ {data_name}æ»šåŠ¨çª—å£èšåˆåˆ†æ")
    print("-" * 40)
    
    # æŒ‰æ—¥æœŸæ’åº
    df_sorted = df.sort_values('æ—¥æœŸ')
    
    # æŒ‰æ—¥æœŸèšåˆæ¯æ—¥é”€å”®é¢
    daily_sales = df_sorted.groupby('æ—¥æœŸ')['é”€å”®é¢'].sum().reset_index()
    
    # è®¡ç®—3æ—¥ç§»åŠ¨å¹³å‡
    daily_sales['3æ—¥ç§»åŠ¨å¹³å‡'] = daily_sales['é”€å”®é¢'].rolling(window=3).mean()
    
    # è®¡ç®—ç´¯è®¡é”€å”®é¢
    daily_sales['ç´¯è®¡é”€å”®é¢'] = daily_sales['é”€å”®é¢'].cumsum()
    
    print("æ¯æ—¥é”€å”®é¢åŠç§»åŠ¨å¹³å‡:")
    print(daily_sales)

def percentage_analysis(df, data_name="æ•°æ®"):
    """
    ç™¾åˆ†æ¯”åˆ†æ
    """
    print(f"\nğŸ“Š {data_name}ç™¾åˆ†æ¯”åˆ†æ")
    print("-" * 40)
    
    # é”€å”®å‘˜é”€å”®é¢å æ¯”
    salesperson_sales = df.groupby('é”€å”®å‘˜')['é”€å”®é¢'].sum()
    total_sales = salesperson_sales.sum()
    salesperson_percentage = (salesperson_sales / total_sales * 100).round(2)
    
    print("é”€å”®å‘˜é”€å”®é¢å æ¯”:")
    for person, percentage in salesperson_percentage.items():
        print(f"  {person}: {salesperson_sales[person]:.2f} ({percentage}%)")
    
    # äº§å“é”€å”®é¢å æ¯”
    product_sales = df.groupby('äº§å“')['é”€å”®é¢'].sum()
    product_percentage = (product_sales / total_sales * 100).round(2)
    
    print(f"\näº§å“é”€å”®é¢å æ¯”:")
    for product, percentage in product_percentage.items():
        print(f"  {product}: {product_sales[product]:.2f} ({percentage}%)")
    
    # åœ°åŒºé”€å”®é¢å æ¯”
    region_sales = df.groupby('åœ°åŒº')['é”€å”®é¢'].sum()
    region_percentage = (region_sales / total_sales * 100).round(2)
    
    print(f"\nåœ°åŒºé”€å”®é¢å æ¯”:")
    for region, percentage in region_percentage.items():
        print(f"  {region}: {region_sales[region]:.2f} ({percentage}%)")

def ranking_analysis(df, data_name="æ•°æ®"):
    """
    æ’ååˆ†æ
    """
    print(f"\nğŸ† {data_name}æ’ååˆ†æ")
    print("-" * 40)
    
    # é”€å”®å‘˜æ’å
    salesperson_ranking = df.groupby('é”€å”®å‘˜')['é”€å”®é¢'].sum().sort_values(ascending=False)
    print("é”€å”®å‘˜é”€å”®é¢æ’å:")
    for rank, (person, sales) in enumerate(salesperson_ranking.items(), 1):
        print(f"  ç¬¬{rank}å: {person} - {sales:.2f}")
    
    # äº§å“é”€å”®é‡æ’å
    product_quantity_ranking = df.groupby('äº§å“')['æ•°é‡'].sum().sort_values(ascending=False)
    print(f"\näº§å“é”€å”®é‡æ’å:")
    for rank, (product, quantity) in enumerate(product_quantity_ranking.items(), 1):
        print(f"  ç¬¬{rank}å: {product} - {quantity}ä»¶")
    
    # åœ°åŒºé”€å”®é¢æ’å
    region_ranking = df.groupby('åœ°åŒº')['é”€å”®é¢'].sum().sort_values(ascending=False)
    print(f"\nåœ°åŒºé”€å”®é¢æ’å:")
    for rank, (region, sales) in enumerate(region_ranking.items(), 1):
        print(f"  ç¬¬{rank}å: {region} - {sales:.2f}")

def save_aggregated_results(df, output_dir):
    """
    ä¿å­˜èšåˆç»“æœ
    """
    print(f"\nğŸ’¾ ä¿å­˜èšåˆåˆ†æç»“æœ")
    print("-" * 40)
    
    try:
        # é”€å”®å‘˜æ±‡æ€»
        salesperson_summary = df.groupby('é”€å”®å‘˜').agg({
            'é”€å”®é¢': ['sum', 'mean', 'count'],
            'æ•°é‡': ['sum', 'mean']
        }).round(2)
        salesperson_file = os.path.join(output_dir, "é”€å”®å‘˜æ±‡æ€».csv")
        salesperson_summary.to_csv(salesperson_file, encoding='utf-8')
        print(f"âœ… é”€å”®å‘˜æ±‡æ€»å·²ä¿å­˜: {salesperson_file}")
        
        # äº§å“æ±‡æ€»
        product_summary = df.groupby('äº§å“').agg({
            'é”€å”®é¢': ['sum', 'mean', 'count'],
            'æ•°é‡': ['sum', 'mean'],
            'å•ä»·': 'mean'
        }).round(2)
        product_file = os.path.join(output_dir, "äº§å“æ±‡æ€».csv")
        product_summary.to_csv(product_file, encoding='utf-8')
        print(f"âœ… äº§å“æ±‡æ€»å·²ä¿å­˜: {product_file}")
        
        # åœ°åŒºæ±‡æ€»
        region_summary = df.groupby('åœ°åŒº').agg({
            'é”€å”®é¢': ['sum', 'mean', 'count'],
            'æ•°é‡': ['sum', 'mean']
        }).round(2)
        region_file = os.path.join(output_dir, "åœ°åŒºæ±‡æ€».csv")
        region_summary.to_csv(region_file, encoding='utf-8')
        print(f"âœ… åœ°åŒºæ±‡æ€»å·²ä¿å­˜: {region_file}")
        
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")

def main():
    """
    ä¸»å‡½æ•° - æ¼”ç¤ºæ•°æ®èšåˆå’Œæ±‡æ€»åˆ†æ
    """
    print("ğŸš€ å¼€å§‹CSVæ•°æ®èšåˆå’Œæ±‡æ€»ç¤ºä¾‹")
    
    # åˆ›å»ºæ‰©å±•ç¤ºä¾‹æ•°æ®
    sales_df = create_extended_sample_data()
    
    print("\n" + "="*60)
    print("ğŸ“Š é”€å”®æ•°æ®èšåˆå’Œæ±‡æ€»åˆ†æ")
    print("="*60)
    
    print("\nåŸå§‹é”€å”®æ•°æ®:")
    print(sales_df.head(10))
    
    # å„ç§èšåˆåˆ†æ
    basic_aggregation(sales_df, "é”€å”®")
    group_by_single_column(sales_df, 'é”€å”®å‘˜', 'é”€å”®é¢', "é”€å”®")
    group_by_single_column(sales_df, 'äº§å“', 'æ•°é‡', "é”€å”®")
    group_by_multiple_columns(sales_df, ['é”€å”®å‘˜', 'äº§å“'], 'é”€å”®é¢', "é”€å”®")
    custom_aggregation(sales_df, "é”€å”®")
    pivot_table_analysis(sales_df, "é”€å”®")
    time_based_aggregation(sales_df, "é”€å”®")
    rolling_aggregation(sales_df, "é”€å”®")
    percentage_analysis(sales_df, "é”€å”®")
    ranking_analysis(sales_df, "é”€å”®")
    
    # ä¿å­˜ç»“æœ
    current_dir = os.path.dirname(os.path.abspath(__file__))
    save_aggregated_results(sales_df, current_dir)
    
    print("\nğŸ‰ æ•°æ®èšåˆå’Œæ±‡æ€»ç¤ºä¾‹å®Œæˆï¼")
    print("\nğŸ“Š åˆ†æå†…å®¹æ€»ç»“:")
    print("1. âœ… åŸºç¡€èšåˆåˆ†æ")
    print("2. âœ… å•åˆ—åˆ†ç»„èšåˆ")
    print("3. âœ… å¤šåˆ—åˆ†ç»„èšåˆ")
    print("4. âœ… è‡ªå®šä¹‰èšåˆå‡½æ•°")
    print("5. âœ… æ•°æ®é€è§†è¡¨åˆ†æ")
    print("6. âœ… æ—¶é—´åºåˆ—èšåˆ")
    print("7. âœ… æ»šåŠ¨çª—å£èšåˆ")
    print("8. âœ… ç™¾åˆ†æ¯”åˆ†æ")
    print("9. âœ… æ’ååˆ†æ")
    print("10. âœ… ç»“æœä¿å­˜")

if __name__ == "__main__":
    main()