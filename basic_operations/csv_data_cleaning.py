#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CSVæ•°æ®æ¸…æ´—ç¤ºä¾‹
ä½¿ç”¨é¢å‘è¿‡ç¨‹ç¼–ç¨‹ï¼Œæ¼”ç¤ºå¸¸è§çš„æ•°æ®æ¸…æ´—æ“ä½œ
"""

import pandas as pd
import numpy as np
import os

def load_data(file_path):
    """
    åŠ è½½CSVæ•°æ®
    """
    try:
        df = pd.read_csv(file_path, encoding='utf-8')
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {df.shape[0]}è¡Œ {df.shape[1]}åˆ—")
        return df
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None

def create_sample_dirty_data():
    """
    åˆ›å»ºåŒ…å«è„æ•°æ®çš„ç¤ºä¾‹æ•°æ®é›†
    """
    print("ğŸ”§ åˆ›å»ºåŒ…å«è„æ•°æ®çš„ç¤ºä¾‹æ•°æ®é›†...")
    
    data = {
        'å§“å': ['å¼ ä¸‰', 'æå››', '', 'ç‹äº”', 'èµµå…­', 'é’±ä¸ƒ', 'å­™å…«', None, 'å‘¨ä¹', 'å´å'],
        'å¹´é¾„': [28, 32, 25, -5, 35, 150, 29, 31, 27, 33],
        'éƒ¨é—¨': ['æŠ€æœ¯éƒ¨', 'é”€å”®éƒ¨', 'æŠ€æœ¯éƒ¨', 'äººäº‹éƒ¨', 'é”€å”®éƒ¨', 'æŠ€æœ¯éƒ¨', 'å¸‚åœºéƒ¨', 'äººäº‹éƒ¨', 'æŠ€æœ¯éƒ¨', 'é”€å”®éƒ¨'],
        'å·¥èµ„': [8000, 6500, 7500, 7000, None, 8500, 6200, 7200, 7800, 6900],
        'é‚®ç®±': ['zhang@company.com', 'li@company', 'wang@company.com', '', 'zhao@company.com', 
                'qian@company.com', 'sun@company.com', 'zhou@company.com', 'wu@company.com', 'wu@company.com']
    }
    
    df = pd.DataFrame(data)
    return df

def check_data_quality(df, data_name="æ•°æ®"):
    """
    æ£€æŸ¥æ•°æ®è´¨é‡
    """
    print(f"\nğŸ” {data_name}è´¨é‡æ£€æŸ¥:")
    print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
    
    # æ£€æŸ¥ç¼ºå¤±å€¼
    missing_count = df.isnull().sum()
    print(f"\nç¼ºå¤±å€¼ç»Ÿè®¡:")
    for col, count in missing_count.items():
        if count > 0:
            print(f"  {col}: {count}ä¸ªç¼ºå¤±å€¼")
    
    # æ£€æŸ¥ç©ºå­—ç¬¦ä¸²
    empty_strings = (df == '').sum()
    print(f"\nç©ºå­—ç¬¦ä¸²ç»Ÿè®¡:")
    for col, count in empty_strings.items():
        if count > 0:
            print(f"  {col}: {count}ä¸ªç©ºå­—ç¬¦ä¸²")
    
    # æ£€æŸ¥é‡å¤è¡Œ
    duplicate_count = df.duplicated().sum()
    print(f"\né‡å¤è¡Œ: {duplicate_count}è¡Œ")
    
    # æ£€æŸ¥æ•°å€¼åˆ—çš„å¼‚å¸¸å€¼
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    if len(numeric_columns) > 0:
        print(f"\næ•°å€¼åˆ—ç»Ÿè®¡:")
        print(df[numeric_columns].describe())

def clean_missing_values(df, strategy='drop'):
    """
    å¤„ç†ç¼ºå¤±å€¼
    å‚æ•°: df - DataFrameå¯¹è±¡
         strategy - å¤„ç†ç­–ç•¥: 'drop', 'fill_mean', 'fill_median', 'fill_mode', 'fill_value'
    """
    print(f"\nğŸ§¹ å¤„ç†ç¼ºå¤±å€¼ (ç­–ç•¥: {strategy})")
    
    if strategy == 'drop':
        # åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„è¡Œ
        cleaned_df = df.dropna()
        print(f"åˆ é™¤ç¼ºå¤±å€¼å: {cleaned_df.shape[0]}è¡Œ")
        
    elif strategy == 'fill_mean':
        # ç”¨å‡å€¼å¡«å……æ•°å€¼åˆ—çš„ç¼ºå¤±å€¼
        cleaned_df = df.copy()
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            mean_value = df[col].mean()
            cleaned_df[col].fillna(mean_value, inplace=True)
            print(f"  {col}åˆ—ç”¨å‡å€¼{mean_value:.2f}å¡«å……")
        
    elif strategy == 'fill_median':
        # ç”¨ä¸­ä½æ•°å¡«å……æ•°å€¼åˆ—çš„ç¼ºå¤±å€¼
        cleaned_df = df.copy()
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            median_value = df[col].median()
            cleaned_df[col].fillna(median_value, inplace=True)
            print(f"  {col}åˆ—ç”¨ä¸­ä½æ•°{median_value:.2f}å¡«å……")
        
    elif strategy == 'fill_mode':
        # ç”¨ä¼—æ•°å¡«å……
        cleaned_df = df.copy()
        for col in df.columns:
            if df[col].isnull().sum() > 0:
                mode_value = df[col].mode()[0] if len(df[col].mode()) > 0 else 'æœªçŸ¥'
                cleaned_df[col].fillna(mode_value, inplace=True)
                print(f"  {col}åˆ—ç”¨ä¼—æ•°'{mode_value}'å¡«å……")
    
    else:
        cleaned_df = df.copy()
    
    return cleaned_df

def clean_empty_strings(df, fill_value='æœªçŸ¥'):
    """
    å¤„ç†ç©ºå­—ç¬¦ä¸²
    """
    print(f"\nğŸ§¹ å¤„ç†ç©ºå­—ç¬¦ä¸² (å¡«å……å€¼: '{fill_value}')")
    
    cleaned_df = df.copy()
    for col in df.columns:
        if df[col].dtype == 'object':  # åªå¤„ç†æ–‡æœ¬åˆ—
            empty_count = (df[col] == '').sum()
            if empty_count > 0:
                cleaned_df[col] = cleaned_df[col].replace('', fill_value)
                print(f"  {col}åˆ—: {empty_count}ä¸ªç©ºå­—ç¬¦ä¸²å·²å¡«å……")
    
    return cleaned_df

def remove_duplicates(df):
    """
    åˆ é™¤é‡å¤è¡Œ
    """
    print(f"\nğŸ§¹ åˆ é™¤é‡å¤è¡Œ")
    
    original_count = len(df)
    cleaned_df = df.drop_duplicates()
    removed_count = original_count - len(cleaned_df)
    
    print(f"åˆ é™¤äº†{removed_count}è¡Œé‡å¤æ•°æ®")
    print(f"æ¸…æ´—å: {len(cleaned_df)}è¡Œ")
    
    return cleaned_df

def clean_outliers(df, column, method='iqr'):
    """
    å¤„ç†å¼‚å¸¸å€¼
    å‚æ•°: df - DataFrameå¯¹è±¡
         column - åˆ—å
         method - å¤„ç†æ–¹æ³•: 'iqr', 'zscore', 'range'
    """
    print(f"\nğŸ§¹ å¤„ç†{column}åˆ—çš„å¼‚å¸¸å€¼ (æ–¹æ³•: {method})")
    
    cleaned_df = df.copy()
    
    if method == 'iqr':
        # ä½¿ç”¨å››åˆ†ä½æ•°æ–¹æ³•
        Q1 = df[column].quantile(0.25)
        Q3 = df[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]
        print(f"  æ£€æµ‹åˆ°{len(outliers)}ä¸ªå¼‚å¸¸å€¼")
        print(f"  æ­£å¸¸èŒƒå›´: {lower_bound:.2f} - {upper_bound:.2f}")
        
        # å°†å¼‚å¸¸å€¼æ›¿æ¢ä¸ºè¾¹ç•Œå€¼
        cleaned_df[column] = cleaned_df[column].clip(lower_bound, upper_bound)
        
    elif method == 'range':
        # ä½¿ç”¨åˆç†èŒƒå›´ï¼ˆé’ˆå¯¹å¹´é¾„ï¼‰
        if column == 'å¹´é¾„':
            lower_bound = 18
            upper_bound = 65
            outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]
            print(f"  æ£€æµ‹åˆ°{len(outliers)}ä¸ªå¼‚å¸¸å€¼")
            print(f"  åˆç†èŒƒå›´: {lower_bound} - {upper_bound}")
            
            # å°†å¼‚å¸¸å€¼æ›¿æ¢ä¸ºè¾¹ç•Œå€¼
            cleaned_df[column] = cleaned_df[column].clip(lower_bound, upper_bound)
    
    return cleaned_df

def validate_email(df, email_column):
    """
    éªŒè¯é‚®ç®±æ ¼å¼
    """
    print(f"\nğŸ§¹ éªŒè¯{email_column}åˆ—çš„é‚®ç®±æ ¼å¼")
    
    cleaned_df = df.copy()
    
    # ç®€å•çš„é‚®ç®±æ ¼å¼éªŒè¯
    email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    
    # æ£€æŸ¥é‚®ç®±æ ¼å¼
    invalid_emails = ~cleaned_df[email_column].str.match(email_pattern, na=False)
    invalid_count = invalid_emails.sum()
    
    print(f"  æ£€æµ‹åˆ°{invalid_count}ä¸ªæ— æ•ˆé‚®ç®±")
    
    if invalid_count > 0:
        print("  æ— æ•ˆé‚®ç®±åˆ—è¡¨:")
        invalid_email_list = cleaned_df[invalid_emails][email_column].tolist()
        for email in invalid_email_list:
            print(f"    - {email}")
        
        # å°†æ— æ•ˆé‚®ç®±æ ‡è®°ä¸ºå¾…ä¿®æ­£
        cleaned_df.loc[invalid_emails, email_column] = 'å¾…ä¿®æ­£'
    
    return cleaned_df

def save_cleaned_data(df, output_path):
    """
    ä¿å­˜æ¸…æ´—åçš„æ•°æ®
    """
    try:
        df.to_csv(output_path, index=False, encoding='utf-8')
        print(f"âœ… æ¸…æ´—åçš„æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")

def main():
    """
    ä¸»å‡½æ•° - æ¼”ç¤ºæ•°æ®æ¸…æ´—æ“ä½œ
    """
    print("ğŸš€ å¼€å§‹CSVæ•°æ®æ¸…æ´—ç¤ºä¾‹")
    
    # åˆ›å»ºåŒ…å«è„æ•°æ®çš„ç¤ºä¾‹
    dirty_df = create_sample_dirty_data()
    
    print("\n" + "="*50)
    print("ğŸ—‚ï¸ åŸå§‹è„æ•°æ®")
    print("="*50)
    print(dirty_df)
    
    # æ£€æŸ¥æ•°æ®è´¨é‡
    check_data_quality(dirty_df, "åŸå§‹")
    
    # å¼€å§‹æ¸…æ´—è¿‡ç¨‹
    print("\n" + "="*50)
    print("ğŸ§¹ å¼€å§‹æ•°æ®æ¸…æ´—è¿‡ç¨‹")
    print("="*50)
    
    # æ­¥éª¤1: å¤„ç†ç©ºå­—ç¬¦ä¸²
    step1_df = clean_empty_strings(dirty_df, 'æœªçŸ¥')
    
    # æ­¥éª¤2: å¤„ç†ç¼ºå¤±å€¼ï¼ˆç”¨ä¼—æ•°å¡«å……ï¼‰
    step2_df = clean_missing_values(step1_df, 'fill_mode')
    
    # æ­¥éª¤3: å¤„ç†å¹´é¾„å¼‚å¸¸å€¼
    step3_df = clean_outliers(step2_df, 'å¹´é¾„', 'range')
    
    # æ­¥éª¤4: éªŒè¯é‚®ç®±æ ¼å¼
    step4_df = validate_email(step3_df, 'é‚®ç®±')
    
    # æ­¥éª¤5: åˆ é™¤é‡å¤è¡Œ
    final_df = remove_duplicates(step4_df)
    
    print("\n" + "="*50)
    print("âœ¨ æ¸…æ´—åçš„æ•°æ®")
    print("="*50)
    print(final_df)
    
    # æ£€æŸ¥æ¸…æ´—åçš„æ•°æ®è´¨é‡
    check_data_quality(final_df, "æ¸…æ´—å")
    
    # ä¿å­˜æ¸…æ´—åçš„æ•°æ®
    current_dir = os.path.dirname(os.path.abspath(__file__))
    output_path = os.path.join(current_dir, "cleaned_data.csv")
    save_cleaned_data(final_df, output_path)
    
    print("\nğŸ‰ æ•°æ®æ¸…æ´—ç¤ºä¾‹å®Œæˆï¼")
    print("\nğŸ“‹ æ¸…æ´—æ­¥éª¤æ€»ç»“:")
    print("1. âœ… å¤„ç†ç©ºå­—ç¬¦ä¸²")
    print("2. âœ… å¤„ç†ç¼ºå¤±å€¼")
    print("3. âœ… å¤„ç†å¹´é¾„å¼‚å¸¸å€¼")
    print("4. âœ… éªŒè¯é‚®ç®±æ ¼å¼")
    print("5. âœ… åˆ é™¤é‡å¤è¡Œ")

if __name__ == "__main__":
    main()